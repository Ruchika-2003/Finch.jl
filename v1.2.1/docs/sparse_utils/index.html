<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Sparse and Structured Utilities · Finch.jl</title><meta name="title" content="Sparse and Structured Utilities · Finch.jl"/><meta property="og:title" content="Sparse and Structured Utilities · Finch.jl"/><meta property="twitter:title" content="Sparse and Structured Utilities · Finch.jl"/><meta name="description" content="Documentation for Finch.jl."/><meta property="og:description" content="Documentation for Finch.jl."/><meta property="twitter:description" content="Documentation for Finch.jl."/><meta property="og:url" content="https://finch-tensor.github.io/Finch.jl/docs/sparse_utils/"/><meta property="twitter:url" content="https://finch-tensor.github.io/Finch.jl/docs/sparse_utils/"/><link rel="canonical" href="https://finch-tensor.github.io/Finch.jl/docs/sparse_utils/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Finch.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Finch.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><span class="tocitem">Documentation</span><ul><li><a class="tocitem" href="../tensor_formats/">Tensor Formats</a></li><li><a class="tocitem" href="../array_api/">High-Level Array API</a></li><li class="is-active"><a class="tocitem" href>Sparse and Structured Utilities</a><ul class="internal"><li><a class="tocitem" href="#Sparse-Constructors"><span>Sparse Constructors</span></a></li><li><a class="tocitem" href="#Fill-Values"><span>Fill Values</span></a></li><li><a class="tocitem" href="#Format-Conversion-and-Storage-Order"><span>Format Conversion and Storage Order</span></a></li></ul></li><li><a class="tocitem" href="../user-defined_functions/">User-Defined Functions</a></li><li><a class="tocitem" href="../fileio/">FileIO</a></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Advanced: Finch Language</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../language/calling_finch/">Calling Finch</a></li><li><a class="tocitem" href="../language/finch_language/">The Finch Language</a></li><li><a class="tocitem" href="../language/dimensionalization/">Dimensionalization</a></li><li><a class="tocitem" href="../language/index_sugar/">Index Sugar</a></li><li><a class="tocitem" href="../language/mask_sugar/">Mask Sugar</a></li><li><a class="tocitem" href="../language/iteration_protocols/">Iteration Protocols</a></li><li><a class="tocitem" href="../language/parallelization/">Parallelization</a></li><li><a class="tocitem" href="../language/interoperability/">Interoperability</a></li><li><a class="tocitem" href="../language/optimization_tips/">Optimization Tips</a></li><li><a class="tocitem" href="../language/benchmarking_tips/">Benchmarking Tips</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox"/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">Developers: Internal Details</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../internals/virtualization/">Virtualization</a></li><li><a class="tocitem" href="../internals/tensor_interface/">Tensor Interface</a></li><li><a class="tocitem" href="../internals/compiler_interface/">Compiler Interfaces</a></li><li><a class="tocitem" href="../internals/finch_notation/">Finch Notation</a></li><li><a class="tocitem" href="../internals/finch_logic/">Finch Logic</a></li></ul></li></ul></li><li><a class="tocitem" href="../../CONTRIBUTING/">Community and Contributions</a></li><li><span class="tocitem">Appendices and Additional Resources</span><ul><li><a class="tocitem" href="../../appendices/directory_structure/">Directory Structure</a></li><li><a class="tocitem" href="../../appendices/directory_structure/">Code Listing</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Documentation</a></li><li class="is-active"><a href>Sparse and Structured Utilities</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Sparse and Structured Utilities</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/finch-tensor/Finch.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/finch-tensor/Finch.jl/blob/main/docs/src/docs/sparse_utils.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Sparse-Array-Utilities"><a class="docs-heading-anchor" href="#Sparse-Array-Utilities">Sparse Array Utilities</a><a id="Sparse-Array-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Array-Utilities" title="Permalink"></a></h1><h2 id="Sparse-Constructors"><a class="docs-heading-anchor" href="#Sparse-Constructors">Sparse Constructors</a><a id="Sparse-Constructors-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Constructors" title="Permalink"></a></h2><p>In addition to the <code>Tensor</code> constructor, Finch provides a number of convenience constructors for common tensor types. For example, the <code>spzeros</code> and <code>sprand</code> functions have <code>fspzeros</code> and <code>fsprand</code> counterparts that return Finch tensors. We can also construct a sparse COO <code>Tensor</code> from a list of indices and values using the <code>fsparse</code> function.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.fsparse" href="#Finch.fsparse"><code>Finch.fsparse</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fsparse(I::Tuple, V,[ M::Tuple, combine]; fill_value=zero(eltype(V)))</code></pre><p>Create a sparse COO tensor <code>S</code> such that <code>size(S) == M</code> and <code>S[(i[q] for i = I)...] = V[q]</code>. The combine function is used to combine duplicates. If <code>M</code> is not specified, it is set to <code>map(maximum, I)</code>. If the combine function is not supplied, combine defaults to <code>+</code> unless the elements of V are Booleans in which case combine defaults to <code>|</code>. All elements of I must satisfy 1 &lt;= I[n][q] &lt;= M[n].  Numerical zeros are retained as structural nonzeros; to drop numerical zeros, use dropzeros!.</p><p>See also: <a href="https://docs.julialang.org/en/v1/stdlib/SparseArrays/#SparseArrays.sparse"><code>sparse</code></a></p><p><strong>Examples</strong></p><p>julia&gt; I = (     [1, 2, 3],     [1, 2, 3],     [1, 2, 3]);</p><p>julia&gt; V = [1.0; 2.0; 3.0];</p><p>julia&gt; fsparse(I, V) SparseCOO (0.0) [1:3×1:3×1:3] │ │ │ └─└─└─[1, 1, 1] [2, 2, 2] [3, 3, 3]       1.0       2.0       3.0</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/fsparse.jl#L1-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.fsparse!" href="#Finch.fsparse!"><code>Finch.fsparse!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fsparse!(I..., V,[ M::Tuple])</code></pre><p>Like <a href="#Finch.fsparse"><code>fsparse</code></a>, but the coordinates must be sorted and unique, and memory is reused.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/fsparse.jl#L74-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.fsprand" href="#Finch.fsprand"><code>Finch.fsprand</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fsprand([rng],[type], M..., p, [rfn])</code></pre><p>Create a random sparse tensor of size <code>m</code> in COO format. There are two cases:     - If <code>p</code> is floating point, the probability of any element being nonzero is     independently given by <code>p</code> (and hence the expected density of nonzeros is     also <code>p</code>).     - If <code>p</code> is an integer, exactly <code>p</code> nonzeros are distributed uniformly at     random throughout the tensor (and hence the density of nonzeros is exactly     <code>p / prod(M)</code>). Nonzero values are sampled from the distribution specified by <code>rfn</code> and have the type <code>type</code>. The uniform distribution is used in case <code>rfn</code> is not specified. The optional <code>rng</code> argument specifies a random number generator.</p><p>See also: (<code>sprand</code>)(https://docs.julialang.org/en/v1/stdlib/SparseArrays/#SparseArrays.sprand)</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; fsprand(Bool, 3, 3, 0.5)
SparseCOO (false) [1:3,1:3]
├─├─[1, 1]: true
├─├─[3, 1]: true
├─├─[2, 2]: true
├─├─[3, 2]: true
├─├─[3, 3]: true

julia&gt; fsprand(Float64, 2, 2, 2, 0.5)
SparseCOO (0.0) [1:2,1:2,1:2]
├─├─├─[2, 2, 1]: 0.6478553157718558
├─├─├─[1, 1, 2]: 0.996665291437684
├─├─├─[2, 1, 2]: 0.7491940599574348</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/fsparse.jl#L96-L128">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.fspzeros" href="#Finch.fspzeros"><code>Finch.fspzeros</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fspzeros([type], M...)</code></pre><p>Create a random zero tensor of size <code>M</code>, with elements of type <code>type</code>. The tensor is in COO format.</p><p>See also: (<code>spzeros</code>)(https://docs.julialang.org/en/v1/stdlib/SparseArrays/#SparseArrays.spzeros)</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; A = fspzeros(Bool, 3, 3)
3×3 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, ElementLevel{false, Bool, Int64, Vector{Bool}}}}:
 0  0  0
 0  0  0
 0  0  0

julia&gt; countstored(A)
0

julia&gt; B = fspzeros(Float64, 2, 2, 2)
2×2×2 Tensor{SparseCOOLevel{3, Tuple{Int64, Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}, Vector{Int64}}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}:
[:, :, 1] =
 0.0  0.0
 0.0  0.0

[:, :, 2] =
 0.0  0.0
 0.0  0.0

julia&gt; countstored(B)
0
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/fsparse.jl#L250-L283">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.ffindnz" href="#Finch.ffindnz"><code>Finch.ffindnz</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ffindnz(arr)</code></pre><p>Return the nonzero elements of <code>arr</code>, as Finch understands <code>arr</code>. Returns <code>(I..., V)</code>, where <code>I</code> are the coordinate vectors, one for each mode of <code>arr</code>, and <code>V</code> is a vector of corresponding nonzero values, which can be passed to <a href="#Finch.fsparse"><code>fsparse</code></a>.</p><p>See also: (<code>findnz</code>)(https://docs.julialang.org/en/v1/stdlib/SparseArrays/#SparseArrays.findnz)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/fsparse.jl#L289-L298">source</a></section></article><h2 id="Fill-Values"><a class="docs-heading-anchor" href="#Fill-Values">Fill Values</a><a id="Fill-Values-1"></a><a class="docs-heading-anchor-permalink" href="#Fill-Values" title="Permalink"></a></h2><p>Finch tensors support an arbitrary &quot;background&quot; value for sparse arrays. While most arrays use <code>0</code> as the background value, this is not always the case. For example, a sparse array of <code>Int</code> might use <code>typemin(Int)</code> as the background value. The <code>fill_value</code> function returns the background value of a tensor. If you ever want to change the background value of an existing array, you can use the <code>set_fill_value!</code> function. The <code>countstored</code> function returns the number of stored elements in a tensor, and calling <code>pattern!</code> on a tensor returns tensor which is true whereever the original tensor stores a value. Note that countstored doesn&#39;t always return the number of non-zero elements in a tensor, as it counts the number of stored elements, and stored elements may include the background value. You can call <code>dropfills!</code> to remove explicitly stored background values from a tensor.</p><pre><code class="language-julia-repl hljs">julia&gt; A = fsparse([1, 1, 2, 3], [2, 4, 5, 6], [1.0, 2.0, 3.0])
3×6 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}:
 0.0  1.0  0.0  2.0  0.0  0.0
 0.0  0.0  0.0  0.0  3.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0

julia&gt; min.(A, -1)
3×6 Tensor{DenseLevel{Int64, DenseLevel{Int64, ElementLevel{-1.0, Float64, Int64, Vector{Float64}}}}}:
 -1.0  -1.0  -1.0  -1.0  -1.0  -1.0
 -1.0  -1.0  -1.0  -1.0  -1.0  -1.0
 -1.0  -1.0  -1.0  -1.0  -1.0  -1.0

julia&gt; fill_value(A)
0.0

julia&gt; B = set_fill_value!(A, -Inf)
3×6 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, ElementLevel{-Inf, Float64, Int64, Vector{Float64}}}}:
 -Inf    1.0  -Inf    2.0  -Inf   -Inf
 -Inf  -Inf   -Inf  -Inf     3.0  -Inf
 -Inf  -Inf   -Inf  -Inf   -Inf   -Inf

julia&gt; min.(B, -1)
3×6 Tensor{SparseDictLevel{Int64, Vector{Int64}, Vector{Int64}, Vector{Int64}, Dict{Tuple{Int64, Int64}, Int64}, Vector{Int64}, SparseDictLevel{Int64, Vector{Int64}, Vector{Int64}, Vector{Int64}, Dict{Tuple{Int64, Int64}, Int64}, Vector{Int64}, ElementLevel{-Inf, Float64, Int64, Vector{Float64}}}}}:
 -Inf   -1.0  -Inf   -1.0  -Inf   -Inf
 -Inf  -Inf   -Inf  -Inf    -1.0  -Inf
 -Inf  -Inf   -Inf  -Inf   -Inf   -Inf

julia&gt; countstored(A)
3

julia&gt; pattern!(A)
3×6 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, PatternLevel{Int64}}}:
 0  1  0  1  0  0
 0  0  0  0  1  0
 0  0  0  0  0  0</code></pre><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.fill_value" href="#Finch.fill_value"><code>Finch.fill_value</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fill_value(arr)</code></pre><p>Return the initializer for <code>arr</code>. For SparseArrays, this is 0. Often, the &quot;fill&quot; value becomes the &quot;background&quot; value of a tensor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/abstract_tensor.jl#L41-L46">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.set_fill_value!" href="#Finch.set_fill_value!"><code>Finch.set_fill_value!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_fill_value!(fbr, init)</code></pre><p>Return a tensor which is equal to <code>fbr</code>, but with the fill (implicit) value set to <code>init</code>.  May reuse memory and render the original tensor unusable when modified.</p><pre><code class="language-julia-repl hljs">julia&gt; A = Tensor(SparseList(Element(0.0), 10), [2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 5.0, 0.0, 6.0, 0.0])
10 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}:
 2.0
 0.0
 3.0
 0.0
 4.0
 0.0
 5.0
 0.0
 6.0
 0.0

julia&gt; set_fill_value!(A, Inf)
10 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{Inf, Float64, Int64, Vector{Float64}}}}:
  2.0
 Inf
  3.0
 Inf
  4.0
 Inf
  5.0
 Inf
  6.0
 Inf</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/tensors/fibers.jl#L188-L222">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.pattern!" href="#Finch.pattern!"><code>Finch.pattern!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">pattern!(fbr)</code></pre><p>Return the pattern of <code>fbr</code>. That is, return a tensor which is true wherever <code>fbr</code> is structurally unequal to its fill_value. May reuse memory and render the original tensor unusable when modified.</p><pre><code class="language-julia-repl hljs">julia&gt; A = Tensor(SparseList(Element(0.0), 10), [2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 5.0, 0.0, 6.0, 0.0])
10 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}:
 2.0
 0.0
 3.0
 0.0
 4.0
 0.0
 5.0
 0.0
 6.0
 0.0

julia&gt; pattern!(A)
10 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, PatternLevel{Int64}}}:
 1
 0
 1
 0
 1
 0
 1
 0
 1
 0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/tensors/levels/pattern_levels.jl#L54-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.countstored" href="#Finch.countstored"><code>Finch.countstored</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">countstored(arr)</code></pre><p>Return the number of stored elements in <code>arr</code>. If there are explicitly stored fill elements, they are counted too.</p><p>See also: (<code>SparseArrays.nnz</code>)(https://docs.julialang.org/en/v1/stdlib/SparseArrays/#SparseArrays.nnz) and (<code>Base.summarysize</code>)(https://docs.julialang.org/en/v1/base/base/#Base.summarysize)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/tensors/fibers.jl#L292-L300">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.dropfills" href="#Finch.dropfills"><code>Finch.dropfills</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">dropfills(src)</code></pre><p>Drop the fill values from <code>src</code> and return a new tensor with the same shape and format.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/copy.jl#L72-L77">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.dropfills!" href="#Finch.dropfills!"><code>Finch.dropfills!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">dropfills!(dst, src)</code></pre><p>Copy only the non-fill values from <code>src</code> into <code>dst</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/interface/copy.jl#L108-L112">source</a></section></article><h3 id="How-to-tell-whether-an-entry-is-&quot;fill&quot;"><a class="docs-heading-anchor" href="#How-to-tell-whether-an-entry-is-&quot;fill&quot;">How to tell whether an entry is &quot;fill&quot;</a><a id="How-to-tell-whether-an-entry-is-&quot;fill&quot;-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-tell-whether-an-entry-is-&quot;fill&quot;" title="Permalink"></a></h3><p>In the sparse world, a semantic distinction is sometimes made between &quot;explicitly stored&quot; values and &quot;implicit&quot; or &quot;fill&quot; values (usually zero). However, the formats in the Finch compiler represent a diverse set of structures beyond sparsity, and it is often unclear whether any of the values in the tensor are &quot;explicit&quot; (consider a mask matrix, which can be represented with a constant number of bits). Thus, Finch makes no semantic distinction between values which are stored explicitly or not. If users wish to make this distinction, they should instead store a tensor of tuples of the form <code>(value, is_fill)</code>. For example,</p><pre><code class="language-julia-repl hljs">julia&gt; A = fsparse(
           [1, 1, 2, 3],
           [2, 4, 5, 6],
           [(1.0, false), (0.0, true), (3.0, false)];
           fill_value=(0.0, true),
       )
3×6 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, ElementLevel{(0.0, true), Tuple{Float64, Bool}, Int64, Vector{Tuple{Float64, Bool}}}}}:
 (0.0, 1)  (1.0, 0)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)
 (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (3.0, 0)  (0.0, 1)
 (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)

julia&gt; B = Tensor(Dense(SparseList(Element((0.0, true)))), A)
3×6 Tensor{DenseLevel{Int64, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{(0.0, true), Tuple{Float64, Bool}, Int64, Vector{Tuple{Float64, Bool}}}}}}:
 (0.0, 1)  (1.0, 0)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)
 (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (3.0, 0)  (0.0, 1)
 (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)  (0.0, 1)

julia&gt; sum(map(last, B))
16

julia&gt; sum(map(first, B))
4.0</code></pre><h2 id="Format-Conversion-and-Storage-Order"><a class="docs-heading-anchor" href="#Format-Conversion-and-Storage-Order">Format Conversion and Storage Order</a><a id="Format-Conversion-and-Storage-Order-1"></a><a class="docs-heading-anchor-permalink" href="#Format-Conversion-and-Storage-Order" title="Permalink"></a></h2><h3 id="Converting-Between-Formats"><a class="docs-heading-anchor" href="#Converting-Between-Formats">Converting Between Formats</a><a id="Converting-Between-Formats-1"></a><a class="docs-heading-anchor-permalink" href="#Converting-Between-Formats" title="Permalink"></a></h3><p>You can convert between tensor formats with the <code>Tensor</code> constructor. Simply construct a new Tensor in the desired format and</p><pre><code class="language-julia-repl hljs">julia&gt; A = Tensor(CSCFormat(), [0 0 2 1; 0 0 1 0; 1 0 0 0])
3×4 Tensor{DenseLevel{Int64, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  2.0  1.0
 0.0  0.0  1.0  0.0
 1.0  0.0  0.0  0.0

julia&gt; B = Tensor(DCSCFormat(), A)
3×4 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  2.0  1.0
 0.0  0.0  1.0  0.0
 1.0  0.0  0.0  0.0</code></pre><h3 id="Storage-Order"><a class="docs-heading-anchor" href="#Storage-Order">Storage Order</a><a id="Storage-Order-1"></a><a class="docs-heading-anchor-permalink" href="#Storage-Order" title="Permalink"></a></h3><p>By default, tensors in Finch are column-major. However, you can use the <code>swizzle</code> function to transpose them lazily. To convert to a transposed format, use the <code>dropfills!</code> function. Note that the <code>permutedims</code> function transposes eagerly.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.swizzle" href="#Finch.swizzle"><code>Finch.swizzle</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">swizzle(tns, dims)</code></pre><p>Create a <code>SwizzleArray</code> to transpose any tensor <code>tns</code> such that</p><pre><code class="nohighlight hljs">    swizzle(tns, dims)[i...] == tns[i[dims]]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/b5a1a87d49365ab6c694d472f72e22586cbd9ce0/src/tensors/combinators/swizzle.jl#L53-L60">source</a></section></article><pre><code class="language-julia-repl hljs">julia&gt; A = Tensor(CSCFormat(), [0 0 2 1; 0 0 1 0; 1 0 0 0])
3×4 Tensor{DenseLevel{Int64, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  2.0  1.0
 0.0  0.0  1.0  0.0
 1.0  0.0  0.0  0.0

julia&gt; tensor_tree(swizzle(A, 2, 1))
SwizzleArray (2, 1)
└─ 3×4-Tensor
   └─ Dense [:,1:4]
      ├─ [:, 1]: SparseList (0.0) [1:3]
      │  └─ [3]: 1.0
      ├─ [:, 2]: SparseList (0.0) [1:3]
      ├─ [:, 3]: SparseList (0.0) [1:3]
      │  ├─ [1]: 2.0
      │  └─ [2]: 1.0
      └─ [:, 4]: SparseList (0.0) [1:3]
         └─ [1]: 1.0

julia&gt; tensor_tree(permutedims(A, (2, 1)))
4×3-Tensor
└─ SparseDict (0.0) [:,1:3]
   ├─ [:, 1]: SparseDict (0.0) [1:4]
   │  ├─ [3]: 2.0
   │  └─ [4]: 1.0
   ├─ [:, 2]: SparseDict (0.0) [1:4]
   │  └─ [3]: 1.0
   └─ [:, 3]: SparseDict (0.0) [1:4]
      └─ [1]: 1.0

julia&gt; dropfills!(swizzle(Tensor(CSCFormat()), 2, 1), A)
3×4 Finch.SwizzleArray{(2, 1), Tensor{DenseLevel{Int64, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}}:
 0.0  0.0  2.0  1.0
 0.0  0.0  1.0  0.0
 1.0  0.0  0.0  0.0</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../array_api/">« High-Level Array API</a><a class="docs-footer-nextpage" href="../user-defined_functions/">User-Defined Functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Friday 28 February 2025 18:24">Friday 28 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
