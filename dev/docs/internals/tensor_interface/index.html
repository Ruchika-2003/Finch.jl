<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tensor Interface · Finch.jl</title><meta name="title" content="Tensor Interface · Finch.jl"/><meta property="og:title" content="Tensor Interface · Finch.jl"/><meta property="twitter:title" content="Tensor Interface · Finch.jl"/><meta name="description" content="Documentation for Finch.jl."/><meta property="og:description" content="Documentation for Finch.jl."/><meta property="twitter:description" content="Documentation for Finch.jl."/><meta property="og:url" content="https://finch-tensor.github.io/Finch.jl/docs/internals/tensor_interface/"/><meta property="twitter:url" content="https://finch-tensor.github.io/Finch.jl/docs/internals/tensor_interface/"/><link rel="canonical" href="https://finch-tensor.github.io/Finch.jl/docs/internals/tensor_interface/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="Finch.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">Finch.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../getting_started/">Getting Started</a></li><li><span class="tocitem">Documentation</span><ul><li><a class="tocitem" href="../../tensor_formats/">Tensor Formats</a></li><li><a class="tocitem" href="../../array_api/">High-Level Array API</a></li><li><a class="tocitem" href="../../sparse_utils/">Sparse and Structured Utilities</a></li><li><a class="tocitem" href="../../user-defined_functions/">User-Defined Functions</a></li><li><a class="tocitem" href="../../fileio/">FileIO</a></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Advanced: Finch Language</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../language/calling_finch/">Calling Finch</a></li><li><a class="tocitem" href="../../language/finch_language/">The Finch Language</a></li><li><a class="tocitem" href="../../language/dimensionalization/">Dimensionalization</a></li><li><a class="tocitem" href="../../language/index_sugar/">Index Sugar</a></li><li><a class="tocitem" href="../../language/mask_sugar/">Mask Sugar</a></li><li><a class="tocitem" href="../../language/iteration_protocols/">Iteration Protocols</a></li><li><a class="tocitem" href="../../language/parallelization/">Parallelization</a></li><li><a class="tocitem" href="../../language/interoperability/">Interoperability</a></li><li><a class="tocitem" href="../../language/optimization_tips/">Optimization Tips</a></li><li><a class="tocitem" href="../../language/benchmarking_tips/">Benchmarking Tips</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox" checked/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">Developers: Internal Details</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../virtualization/">Virtualization</a></li><li class="is-active"><a class="tocitem" href>Tensor Interface</a><ul class="internal"><li><a class="tocitem" href="#Tensor-Methods"><span>Tensor Methods</span></a></li><li class="toplevel"><a class="tocitem" href="#Level-Interface"><span>Level Interface</span></a></li><li><a class="tocitem" href="#Types-and-Storage-of-Level"><span>Types and Storage of Level</span></a></li><li><a class="tocitem" href="#Level-Methods"><span>Level Methods</span></a></li><li class="toplevel"><a class="tocitem" href="#Combinator-Interface"><span>Combinator Interface</span></a></li></ul></li><li><a class="tocitem" href="../compiler_interface/">Compiler Interfaces</a></li><li><a class="tocitem" href="../finch_notation/">Finch Notation</a></li><li><a class="tocitem" href="../finch_logic/">Finch Logic</a></li></ul></li></ul></li><li><a class="tocitem" href="../../../CONTRIBUTING/">Community and Contributions</a></li><li><span class="tocitem">Appendices and Additional Resources</span><ul><li><a class="tocitem" href="../../../appendices/directory_structure/">Directory Structure</a></li><li><a class="tocitem" href="../../../appendices/directory_structure/">Code Listing</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Documentation</a></li><li><a class="is-disabled">Developers: Internal Details</a></li><li class="is-active"><a href>Tensor Interface</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tensor Interface</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/finch-tensor/Finch.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/finch-tensor/Finch.jl/blob/main/docs/src/docs/internals/tensor_interface.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tensor-Interface"><a class="docs-heading-anchor" href="#Tensor-Interface">Tensor Interface</a><a id="Tensor-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Tensor-Interface" title="Permalink"></a></h1><p>The <code>AbstractTensor</code> interface (defined in <code>src/abstract_tensor.jl</code>) is the interface through which Finch understands tensors. It is a high-level interace which allows tensors to interact with the rest of the Finch system. The interface is designed to be extensible, allowing users to define their own tensor types and behaviors. For a minimal example, read the definitions in <a href="https://github.com/finch-tensor/Finch.jl/blob/main/ext/SparseArraysExt.jl"><code>/ext/SparseArraysExt.jl</code></a> and in <a href="https://github.com/finch-tensor/Finch.jl/blob/main/src/interface/abstractarray.jl"><code>/src/interface/abstractarray.jl</code></a>. Once these methods are defined that tell Finch how to generate code for an array, the <code>AbstractTensor</code> interface will also use Finch to generate code for several Julia <code>AbstractArray</code> methods, such as <code>getindex</code>, <code>setindex!</code>, <code>map</code>, and <code>reduce</code>. An important note: <code>getindex</code> and <code>setindex!</code> are not a source of truth for Finch tensors. Search the codebase for <code>::AbstractTensor</code> for a full list of methods that are implemented for <code>AbstractTensor</code>. Note than most <code>AbstractTensor</code> implement <code>labelled_show</code> and <code>labelled_children</code> methods instead of <code>show(::IO, ::MIME&quot;text/plain&quot;, t::AbstractTensor)</code> for pretty printed display.</p><h2 id="Tensor-Methods"><a class="docs-heading-anchor" href="#Tensor-Methods">Tensor Methods</a><a id="Tensor-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Tensor-Methods" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.declare!" href="#Finch.declare!"><code>Finch.declare!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">declare!(ctx, tns, init)</code></pre><p>Declare the read-only virtual tensor <code>tns</code> in the context <code>ctx</code> with a starting value of <code>init</code> and return it. Afterwards the tensor is update-only.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L4-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.freeze!" href="#Finch.freeze!"><code>Finch.freeze!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">freeze!(ctx, tns)</code></pre><p>Freeze the update-only virtual tensor <code>tns</code> in the context <code>ctx</code> and return it. This may involve trimming any excess overallocated memory.  Afterwards, the tensor is read-only.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L20-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.thaw!" href="#Finch.thaw!"><code>Finch.thaw!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">thaw!(ctx, tns)</code></pre><p>Thaw the read-only virtual tensor <code>tns</code> in the context <code>ctx</code> and return it. Afterwards, the tensor is update-only.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L29-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.unfurl" href="#Finch.unfurl"><code>Finch.unfurl</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">unfurl(ctx, tns, ext, proto)</code></pre><p>Return an array object (usually a looplet nest) for lowering the outermost dimension of virtual tensor <code>tns</code>. <code>ext</code> is the extent of the looplet. <code>proto</code> is the protocol that should be used for this index, but one doesn&#39;t need to unfurl all the indices at once.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/lower.jl#L270-L276">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.instantiate" href="#Finch.instantiate"><code>Finch.instantiate</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">instantiate(ctx, tns, mode)</code></pre><p>Process the tensor <code>tns</code> in the context <code>ctx</code>, just after it has been unfurled, declared, or thawed. The earliest opportunity to process <code>tns</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L12-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.virtual_eltype" href="#Finch.virtual_eltype"><code>Finch.virtual_eltype</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">virtual_eltype(arr)</code></pre><p>Return the element type of the virtual tensor <code>arr</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L52-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.virtual_fill_value" href="#Finch.virtual_fill_value"><code>Finch.virtual_fill_value</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">virtual fill_value(arr)</code></pre><p>Return the initializer for virtual array <code>arr</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L45-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.virtual_size" href="#Finch.virtual_size"><code>Finch.virtual_size</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">virtual_size(ctx, tns)</code></pre><p>Return a tuple of the dimensions of <code>tns</code> in the context <code>ctx</code>. This is a function similar in spirit to <code>Base.axes</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L71-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.virtual_resize!" href="#Finch.virtual_resize!"><code>Finch.virtual_resize!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">virtual_resize!(ctx, tns, dims...)</code></pre><p>Resize <code>tns</code> in the context <code>ctx</code>. This is a function similar in spirit to <code>Base.resize!</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L79-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.moveto" href="#Finch.moveto"><code>Finch.moveto</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">moveto(arr, device)</code></pre><p>If the array is not on the given device, it creates a new version of this array on that device and copies the data in to it, according to the <code>device</code> trait.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L87-L92">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.virtual_moveto" href="#Finch.virtual_moveto"><code>Finch.virtual_moveto</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">virtual_moveto(device, arr)</code></pre><p>If the virtual array is not on the given device, copy the array to that device. This function may modify underlying data arrays, but cannot change the virtual itself. This function is used to move data to the device before a kernel is launched.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L95-L101">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.labelled_show" href="#Finch.labelled_show"><code>Finch.labelled_show</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">labelled_show(node)</code></pre><p>Show the <code>node</code> in a <code>LabelledTree</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L118-L122">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.labelled_children" href="#Finch.labelled_children"><code>Finch.labelled_children</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">labelled_children(node)</code></pre><p>Return the children of <code>node</code> in a <code>LabelledTree</code>. You may label the children by returning a <code>LabelledTree(key, value)</code>, which will be shown as <code>key: value</code> a.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/abstract_tensor.jl#L126-L131">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.is_injective" href="#Finch.is_injective"><code>Finch.is_injective</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">is_injective(ctx, tns)</code></pre><p>Returns a vector of booleans, one for each dimension of the tensor, indicating whether the access is injective in that dimension.  A dimension is injective if each index in that dimension maps to a different memory space in the underlying array.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/transforms/concurrent.jl#L5-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.is_atomic" href="#Finch.is_atomic"><code>Finch.is_atomic</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">is_atomic(ctx, tns)

Returns a tuple (atomicities, overall) where atomicities is a vector, indicating which indices have an atomic that guards them,
and overall is a boolean that indicates is the last level had an atomic guarding it.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/transforms/concurrent.jl#L15-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.is_concurrent" href="#Finch.is_concurrent"><code>Finch.is_concurrent</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">is_concurrent(ctx, tns)

Returns a vector of booleans, one for each dimension of the tensor, indicating
whether the index can be written to without any execution state. So if a matrix returns [true, false],
then we can write to A[i, j] and A[i_2, j] without any shared execution state between the two, but
we can&#39;t write to A[i, j] and A[i, j_2] without carrying over execution state.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/transforms/concurrent.jl#L23-L30">source</a></section></article><h1 id="Level-Interface"><a class="docs-heading-anchor" href="#Level-Interface">Level Interface</a><a id="Level-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Level-Interface" title="Permalink"></a></h1><pre><code class="language-julia-repl hljs">julia&gt; A = [0.0 0.0 4.4; 1.1 0.0 0.0; 2.2 0.0 5.5; 3.3 0.0 0.0]
4×3 Matrix{Float64}:
 0.0  0.0  4.4
 1.1  0.0  0.0
 2.2  0.0  5.5
 3.3  0.0  0.0

julia&gt; A_fbr = Tensor(Dense(Dense(Element(0.0))), A)
4×3 Tensor{DenseLevel{Int64, DenseLevel{Int64, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  4.4
 1.1  0.0  0.0
 2.2  0.0  5.5
 3.3  0.0  0.0

julia&gt; tensor_tree(A_fbr)
4×3-Tensor
└─ Dense [:,1:3]
   ├─ [:, 1]: Dense [1:4]
   │  ├─ [1]: 0.0
   │  ├─ [2]: 1.1
   │  ├─ [3]: 2.2
   │  └─ [4]: 3.3
   ├─ [:, 2]: Dense [1:4]
   │  ├─ [1]: 0.0
   │  ├─ [2]: 0.0
   │  ├─ [3]: 0.0
   │  └─ [4]: 0.0
   └─ [:, 3]: Dense [1:4]
      ├─ [1]: 4.4
      ├─ [2]: 0.0
      ├─ [3]: 5.5
      └─ [4]: 0.0</code></pre><p>We refer to a node in the tree as a subfiber. All of the nodes at the same level are stored in the same datastructure, and disambiguated by an integer <code>position</code>.  in the above example, there are three levels: the rootmost level contains only one subfiber, the root. The middle level has 3 subfibers, one for each column. The leafmost level has 12 subfibers, one for each element of the array.  For example, the first level is <code>A_fbr.lvl</code>, and we can represent it&#39;s third position as <code>SubFiber(A_fbr.lvl.lvl, 3)</code>. The second level is <code>A_fbr.lvl.lvl</code>, and we can access it&#39;s 9th position as <code>SubFiber(A_fbr.lvl.lvl.lvl, 9)</code>. For instructional purposes, you can use parentheses to call a subfiber on an index to select among children of a subfiber.</p><pre><code class="language-julia-repl hljs">julia&gt; tensor_tree(Finch.SubFiber(A_fbr.lvl.lvl, 3))
Dense [1:4]
├─ [1]: 4.4
├─ [2]: 0.0
├─ [3]: 5.5
└─ [4]: 0.0

julia&gt; tensor_tree(A_fbr[:, 3])
4-Tensor
└─ Dense [1:4]
   ├─ [1]: 4.4
   ├─ [2]: 0.0
   ├─ [3]: 5.5
   └─ [4]: 0.0

julia&gt; tensor_tree(A_fbr(3))
Dense [1:4]
├─ [1]: 4.4
├─ [2]: 0.0
├─ [3]: 5.5
└─ [4]: 0.0

julia&gt; Finch.SubFiber(A_fbr.lvl.lvl.lvl, 9)
 Finch.SubFiber{ElementLevel{0.0, Float64, Int64, Vector{Float64}}, Int64}:
4.4

julia&gt; A_fbr[1, 3]
4.4

julia&gt; A_fbr(3)(1)
4.4
</code></pre><p>When we print the tree in text, positions are numbered from top to bottom.</p><p>Because our array is sparse, (mostly zero, or another fill value), it would be more efficient to store only the nonzero values. In Finch, each level is represented with a different format. A sparse level only stores non-fill values. This time, we&#39;ll use a tensor constructor with <code>sl</code> (for &quot;<code>SparseList</code> of nonzeros&quot;) instead of <code>d</code> (for &quot;<code>Dense</code>&quot;):</p><pre><code class="language-julia-repl hljs">julia&gt; A_fbr = Tensor(Dense(SparseList(Element(0.0))), A)
4×3 Tensor{DenseLevel{Int64, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  4.4
 1.1  0.0  0.0
 2.2  0.0  5.5
 3.3  0.0  0.0

julia&gt; tensor_tree(A_fbr)
4×3-Tensor
└─ Dense [:,1:3]
   ├─ [:, 1]: SparseList (0.0) [1:4]
   │  ├─ [2]: 1.1
   │  ├─ [3]: 2.2
   │  └─ [4]: 3.3
   ├─ [:, 2]: SparseList (0.0) [1:4]
   └─ [:, 3]: SparseList (0.0) [1:4]
      ├─ [1]: 4.4
      └─ [3]: 5.5
</code></pre><p>Our <code>Dense(SparseList(Element(0.0)))</code> format is also known as <a href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_.28CSC_or_CCS.29">&quot;CSC&quot;</a> and is equivalent to <a href="https://sparsearrays.juliasparse.org/dev/#man-csc"><code>SparseMatrixCSC</code></a>. The <a href="../../tensor_formats/#Finch.Tensor"><code>Tensor</code></a> function will perform a zero-cost copy between Finch fibers and sparse matrices, when available.  CSC is an excellent general-purpose representation when we expect most of the columns to have a few nonzeros. However, when most of the columns are entirely fill (a situation known as hypersparsity), it is better to compress the root level as well:</p><pre><code class="language-julia-repl hljs">julia&gt; A_fbr = Tensor(SparseList(SparseList(Element(0.0))), A)
4×3 Tensor{SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, SparseListLevel{Int64, Vector{Int64}, Vector{Int64}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}}:
 0.0  0.0  4.4
 1.1  0.0  0.0
 2.2  0.0  5.5
 3.3  0.0  0.0

julia&gt; tensor_tree(A_fbr)
4×3-Tensor
└─ SparseList (0.0) [:,1:3]
   ├─ [:, 1]: SparseList (0.0) [1:4]
   │  ├─ [2]: 1.1
   │  ├─ [3]: 2.2
   │  └─ [4]: 3.3
   └─ [:, 3]: SparseList (0.0) [1:4]
      ├─ [1]: 4.4
      └─ [3]: 5.5
</code></pre><p>Here we see that the entirely zero column has also been compressed. The <code>SparseList(SparseList(Element(0.0)))</code> format is also known as <a href="https://ieeexplore.ieee.org/document/4536313">&quot;DCSC&quot;</a>.</p><p>The <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html">&quot;COO&quot;</a> (or &quot;Coordinate&quot;) format is often used in practice for ease of interchange between libraries. In an <code>N</code>-dimensional array <code>A</code>, COO stores <code>N</code> lists of indices <code>I_1, ..., I_N</code> where <code>A[I_1[p], ..., I_N[p]]</code> is the <code>p</code>^th stored value in column-major numbering. In Finch, <code>COO</code> is represented as a multi-index level, which can handle more than one index at once. We use curly brackets to declare the number of indices handled by the level:</p><pre><code class="language-julia-repl hljs">julia&gt; A_fbr = Tensor(SparseCOO{2}(Element(0.0)), A)
4×3 Tensor{SparseCOOLevel{2, Tuple{Int64, Int64}, Vector{Int64}, Tuple{Vector{Int64}, Vector{Int64}}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}}:
 0.0  0.0  4.4
 1.1  0.0  0.0
 2.2  0.0  5.5
 3.3  0.0  0.0

julia&gt; tensor_tree(A_fbr)
4×3-Tensor
└─ SparseCOO{2} (0.0) [:,1:3]
   ├─ [2, 1]: 1.1
   ├─ [3, 1]: 2.2
   ├─ ⋮
   ├─ [1, 3]: 4.4
   └─ [3, 3]: 5.5
</code></pre><p>The COO format is compact and straightforward, but doesn&#39;t support random access. For random access, one should use the <code>SparseDict</code> or <code>SparseBytemap</code> format. A full listing of supported formats is described after a rough description of shared common internals of level, relating to types and storage.</p><h2 id="Types-and-Storage-of-Level"><a class="docs-heading-anchor" href="#Types-and-Storage-of-Level">Types and Storage of Level</a><a id="Types-and-Storage-of-Level-1"></a><a class="docs-heading-anchor-permalink" href="#Types-and-Storage-of-Level" title="Permalink"></a></h2><p>All levels have a <code>postype</code>, typically denoted as <code>Tp</code> in the constructors, used for internal pointer types but accessible by the function:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.postype" href="#Finch.postype"><code>Finch.postype</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">postype(lvl)</code></pre><p>Return a position type with the same flavor as those used to store the positions of the fibers contained in <code>lvl</code>. The name position descends from the pos or position or pointer arrays found in many definitions of CSR or CSC. In Finch, positions should be data used to access either a subfiber or some other similar auxiliary data. Thus, we often end up iterating over positions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L109-L115">source</a></section></article><p>Additionally, many levels have a <code>Vp</code> or <code>Vi</code> in their constructors; these stand for vector of element type <code>Tp</code> or <code>Ti</code>. More generally, levels are paramterized by the types that they use for storage. By default, all levels use <code>Vector</code>, but a user could could change any or all of the storage types of a tensor so that the tensor would be stored on a GPU or CPU or some combination thereof, or even just via a vector with a different allocation mechanism.  The storage type should behave like <code>AbstractArray</code> and needs to implement the usual abstract array functions and <code>Base.resize!</code>. See the tests for an example.</p><p>When levels are constructed in short form as in the examples above, the index, position, and storage types are inferred from the level below. All the levels at the bottom of a Tensor (<code>Element, Pattern, Repeater</code>) specify an index type, position type, and storage type even if they don&#39;t need them. These are used by levels that take these as parameters.</p><h2 id="Level-Methods"><a class="docs-heading-anchor" href="#Level-Methods">Level Methods</a><a id="Level-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Level-Methods" title="Permalink"></a></h2><p>Tensor levels are implemented using the following methods:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.declare_level!" href="#Finch.declare_level!"><code>Finch.declare_level!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">declare_level!(ctx, lvl, pos, init)</code></pre><p>Initialize and thaw all fibers within <code>lvl</code>, assuming positions <code>1:pos</code> were previously assembled and frozen. The resulting level has no assembled positions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L60-L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.assemble_level!" href="#Finch.assemble_level!"><code>Finch.assemble_level!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">assemble_level!(ctx, lvl, pos, new_pos)</code></pre><p>Assemble and positions <code>pos+1:new_pos</code> in <code>lvl</code>, assuming positions <code>1:pos</code> were previously assembled.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L86-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.reassemble_level!" href="#Finch.reassemble_level!"><code>Finch.reassemble_level!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">reassemble_level!(lvl, ctx, pos_start, pos_end)</code></pre><p>Set the previously assempled positions from <code>pos_start</code> to <code>pos_end</code> to <code>level_fill_value(lvl)</code>.  Not avaliable on all level types as this presumes updating.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.freeze_level!" href="#Finch.freeze_level!"><code>Finch.freeze_level!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">freeze_level!(ctx, lvl, pos, init)</code></pre><p>Given the last reference position, <code>pos</code>, freeze all fibers within <code>lvl</code> assuming that we have potentially updated <code>1:pos</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L68-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.level_ndims" href="#Finch.level_ndims"><code>Finch.level_ndims</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">level_ndims(::Type{Lvl})</code></pre><p>The result of <code>level_ndims(Lvl)</code> defines <a href="https://docs.julialang.org/en/v1/base/arrays/#Base.ndims">ndims</a> for all subfibers in a level of type <code>Lvl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L19-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.level_size" href="#Finch.level_size"><code>Finch.level_size</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">level_size(lvl)</code></pre><p>The result of <code>level_size(lvl)</code> defines the <a href="https://docs.julialang.org/en/v1/base/arrays/#Base.size">size</a> of all subfibers in the level <code>lvl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L27-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.level_axes" href="#Finch.level_axes"><code>Finch.level_axes</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">level_axes(lvl)</code></pre><p>The result of <code>level_axes(lvl)</code> defines the <a href="https://docs.julialang.org/en/v1/base/arrays/#Base.axes-Tuple{Any}">axes</a> of all subfibers in the level <code>lvl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L35-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.level_eltype" href="#Finch.level_eltype"><code>Finch.level_eltype</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">level_eltype(::Type{Lvl})</code></pre><p>The result of <code>level_eltype(Lvl)</code> defines <a href="https://docs.julialang.org/en/v1/base/collections/#Base.eltype"><code>eltype</code></a> for all subfibers in a level of type <code>Lvl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L43-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Finch.level_fill_value" href="#Finch.level_fill_value"><code>Finch.level_fill_value</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">level_fill_value(::Type{Lvl})</code></pre><p>The result of <code>level_fill_value(Lvl)</code> defines <a href="../../sparse_utils/#Finch.fill_value"><code>fill_value</code></a> for all subfibers in a level of type <code>Lvl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/finch-tensor/Finch.jl/blob/7ea378a88dc22864e1199a2def155db4bda585ab/src/tensors/abstract_level.jl#L52-L57">source</a></section></article><h1 id="Combinator-Interface"><a class="docs-heading-anchor" href="#Combinator-Interface">Combinator Interface</a><a id="Combinator-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Combinator-Interface" title="Permalink"></a></h1><p>Tensor Combinators allow us to modify the behavior of tensors. The <code>AbstractCombinator</code> interface (defined in <a href="https://github.com/finch-tensor/Finch.jl/blob/main/src/tensors/abstract_combinator.jl"><code>src/tensors/abstract_combinator.jl</code></a>) is the interface through which Finch understands tensor combinators. The interface requires the combinator to overload all of the tensor methods, as well as the methods used by Looplets when lowering ranges, etc. For a minimal example, read the definitions in <a href="https://github.com/finch-tensor/Finch.jl/blob/main/src/tensors/combinators/offset.jl"><code>/src/tensors/combinators/offset.jl</code></a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../virtualization/">« Virtualization</a><a class="docs-footer-nextpage" href="../compiler_interface/">Compiler Interfaces »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Saturday 28 December 2024 18:58">Saturday 28 December 2024</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
